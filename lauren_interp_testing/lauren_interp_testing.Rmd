---
title: "lauren-interp-testing"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(stats)
```


```{r}
# Run the 01_createDataFrameScript.R before running this, to get the variables into the environment. 
# I've spent enough time fighting R that I'm not dealing with import/export right now.

#Spot-checking different samples, it's 5:30 and I have not gotten nearly enough sleep to run all 28 right now.

fisk_10 <- reformattedData$`FISK-10.0` %>%
  pivot_longer(everything(), names_to = "wavenumber", values_to = "absorbance")


fisk_110 <- reformattedData$`FISK-110.0` %>%
  pivot_longer(everything(), names_to = "wavenumber", values_to = "absorbance")

LSA2_35 <- reformattedData$`LSA2-35.0` %>%
  pivot_longer(everything(), names_to = "wavenumber", values_to = "absorbance")


NANB3A2_10_5 <- reformattedData$`NANB3A1-131.5.0` %>%
  pivot_longer(everything(), names_to = "wavenumber", values_to = "absorbance")

NANDB_4 <- reformattedData$`NAN-DB-4.0` %>%
  pivot_longer(everything(), names_to = "wavenumber", values_to = "absorbance")

SS <- reformattedData$`SS.0` %>%
  pivot_longer(everything(), names_to = "wavenumber", values_to = "absorbance")

WQ <- reformattedData$`WQ.0` %>%
  pivot_longer(everything(), names_to = "wavenumber", values_to = "absorbance")
```


```{r fisk_10}
ggplot(fisk_10, aes(x = as.numeric(wavenumber), y = absorbance)) + geom_point()

#A bit of weird noise from the ~4500-Max range, zooming
ggplot(fisk_10, aes(x = as.numeric(wavenumber), y = absorbance)) + geom_point() + xlim(6000,8000) + ylim(0.0,0.05)

#Some other weird noise at x < 500
ggplot(fisk_10, aes(x = as.numeric(wavenumber), y = absorbance)) + geom_point() + xlim(0,2000)

```


```{r fisk_110}
ggplot(fisk_110, aes(x = as.numeric(wavenumber), y = absorbance)) + geom_point()

#Similar weird noise in the same range on this one. May want to exclude these ranges, definitely not suitable for interpolation here.
ggplot(fisk_110, aes(x = as.numeric(wavenumber), y = absorbance)) + geom_point() + xlim(6000,8000) + ylim(-.025, 0.01)

```

```{r LSA2-35}
ggplot(LSA2_35, aes(x = as.numeric(wavenumber), y = absorbance)) + geom_point()

#Yeah, definitely need to limit the data range.
ggplot(LSA2_35, aes(x = as.numeric(wavenumber), y = absorbance)) + geom_point() + xlim(5500,8000) + ylim(-.01,.01)
```

```{r NANB3A1-131.5.0}
ggplot(NANB3A2_10_5, aes(x = as.numeric(wavenumber), y = absorbance)) + geom_point()

#The noise distribution is a bit different here, with the distortion reaching down into the 4500 range but it being a tighter spread the entire way
ggplot(NANB3A2_10_5, aes(x = as.numeric(wavenumber), y = absorbance)) + geom_point() + xlim(4500,8000) + ylim(-.02,0.02)
```


```{r NAN-DB-4.0}
ggplot(NANDB_4, aes(x = as.numeric(wavenumber), y = absorbance)) + geom_point()

ggplot(NANDB_4, aes(x = as.numeric(wavenumber), y = absorbance)) + geom_point() + xlim(4500,8000) + ylim(-.02,0.02)
```

```{r SS}
# I'm beginning to think I get why the model is as rough as it is...
ggplot(SS, aes(x = as.numeric(wavenumber), y = absorbance)) + geom_point()

# ThisIsFine.jpg
ggplot(SS, aes(x = as.numeric(wavenumber), y = absorbance)) + geom_point() + xlim(4000,8000) + ylim(-.045,.025)
```

```{r WQ}
# yikes
ggplot(WQ, aes(x = as.numeric(wavenumber), y = absorbance)) + geom_point()
```


## Interpolation Testing - Wet Quartz

```{r interp-wq}
WQ <- WQ %>%
  mutate(wavenumber = as.numeric(wavenumber))

approxWQ <- approx(WQ, n = 10000) %>%
  as.data.frame(.)

#I'd say that I trust the approximation up until wavenumber 5000, at which point the frame should be cropped.

ggplot(approxWQ, aes(x = x, y = y)) + geom_point() + xlim(4500,5500) + ylim(-.025,.025)
ggplot(WQ, aes(x = as.numeric(wavenumber), y = absorbance)) + geom_point() + xlim(4500,5500) + ylim(-.025,.025)


# but in general it follows the line very well, even at the beginning
#it looks sus as hell on the graph but when you zoom in it's still smooth. I'd put a cautious limit at 400.  
ggplot(approxWQ, aes(x = x, y = y)) + geom_point() + xlim(250,1000) 
ggplot(WQ, aes(x = as.numeric(wavenumber), y = absorbance)) + geom_point() + xlim(250,1000)

```

```{r interp-nandb}
NANDB_4 <- NANDB_4 %>%
  mutate(wavenumber = as.numeric(wavenumber))

approxDB <- approx(NANDB_4, n = 10000) %>%
  as.data.frame(.)

ggplot(approxDB, aes(x = x, y = y)) + geom_point() 
ggplot(NANDB_4, aes(x = wavenumber, y = absorbance)) + geom_point() 

#Again, I'd be comfortable with this up to the 5000 point. 
ggplot(approxDB, aes(x = x, y = y)) + geom_point() + xlim(4500,5500) + ylim(-.025,.025)
ggplot(NANDB_4, aes(x = wavenumber, y = absorbance)) + geom_point() + xlim(4500,5500) + ylim(-.025,.025)

```

```{r approxfun_testing}
# Approxfun defines a function interpolating the data
# that can then be called on another vector of wavenumbers to return the approximations
f1 <- approxfun(NANDB_4)
test <- c(1000,2000,3000,4000,5000,6000)
f1(test)
```

```{r alaska_interpolation_testing}
AK_1 <- read_csv("Samples/alaska_csv/AS-01\ (8_24_16).0.csv")
GL_1 <- read_csv("Samples/greenland_csv/FISK-10.0.csv")

ak_min <- min(AK_1$wavenumber)
ak_max <- max(AK_1$wavenumber)
gl_min <- min(GL_1$wavenumber)
gl_max <- max(GL_1$wavenumber)

# Cutting Greenland data down to >4k, round to 1 decimal point
GL_filtered <- GL_1 %>%
  filter(wavenumber <= 3996.4) %>%
  mutate(wavenumber = signif(wavenumber,digits = 5))
# Checking that each wavenumber is unique
length(unique(GL_filtered$wavenumber)) == nrow(GL_filtered)

# Rounding Alaska to 1 decimal
AK_filtered <- AK_1%>%
  mutate(wavenumber = signif(wavenumber, digits = 5))
# Checking that each wavenumber is unique
length(unique(AK_filtered$wavenumber)) == nrow(AK_filtered)


# Ok, that's a problem. Interpolation it is. Alas for the easy route. 
wavenum_test <- GL_filtered %>%
  full_join(AK_filtered, by = 'wavenumber')
```


```{r greenland_err_testing}
#reading in the greenland data, with one change for the csv conversion
fname <- list.files("Samples/greenland_csv", full.names = T)
filelist <- lapply(fname, read_csv)
names(filelist) <- gsub(".*/(.*)\\..*", "\\1", fname)

# Removing the redundant index variable
filelist <- lapply(filelist, function(x){select(x, wavenumber, absorbance)})
# Reformatting the data...
reformattedData <- lapply(filelist, function(x){pivot_wider(x, names_from = wavenumber, values_from = absorbance)})
# Adding the names back
wavenumber_matrix <- lapply(reformattedData, names)
# Rounding all to two digits past the decimal 
#wavenumber_matrix_trunc <- lapply(wavenumber_matrix, function(x){round(as.numeric(x), digits = 2)})
wavenumber_df <- as.data.frame(wavenumber_matrix)

#Calculating max and min values for each wavenumber observation across Greenland
wavenumber_df$max <- apply(wavenumber_df, 1, function(x){max(x)})
wavenumber_df$min <- apply(wavenumber_df, 1, function(x){min(x)})
#Calculating the largest difference in wavenumber for each observation
wavenumber_df <- wavenumber_df %>%
  mutate(noise_test = as.numeric(max) - as.numeric(min))

#The biggest error we have is 0.0293, which is not bad. This is across the entirety of greenland. 
max_err <- max(wavenumber_df$noise_test)
```

```{r alaska_err_testing}
#reading in the Alaska data, with one change for the csv conversion
a_fname <- list.files("Samples/alaska_csv", full.names = T)
a_filelist <- lapply(a_fname, read_csv)

#Cleaning up the names. If one of you knows how to do this in one regex and not two, go ahead. I can't.
# Removing the filepath
names(a_filelist) <- gsub("Samples/alaska_csv/", "", a_fname)
# Removing the space, date, and csv ending
names(a_filelist) <- gsub(" (.*).0.csv","", names(a_filelist))

# Removing the redundant index variable
a_filelist <- lapply(a_filelist, function(x){select(x, wavenumber, absorbance)})
# Reformatting the data...
ak_reformattedData <- lapply(a_filelist, function(x){pivot_wider(x, names_from = wavenumber, values_from = absorbance)})
#Getting only the wavenumber
wavenumber_matrix_ak <- lapply(ak_reformattedData, names)
# Rounding all to two digits past the decimal - deprecated
#wavenumber_matrix_trunc <- lapply(wavenumber_matrix_ak, function(x){round(as.numeric(x), digits = 2)})
wavenumber_df_ak <- as.data.frame(wavenumber_matrix_ak)

#Calculating max and min values for each wavenumber observation across Alaska
wavenumber_df_ak$max <- apply(wavenumber_df_ak, 1, function(x){max(x)})
wavenumber_df_ak$min <- apply(wavenumber_df_ak, 1, function(x){min(x)})
#Calculating the largest difference in wavenumber for each observation
wavenumber_df_ak <- wavenumber_df_ak %>%
  mutate(noise_test = as.numeric(max) - as.numeric(min))

#The alaska samples have no noise whatsoever in the wavenumber reading. That's only a greenland problem. 
#Honestly, this means we should probably interpolate Greenland to match Alaska and not the other way around. 
max_err_alaska <- max(wavenumber_df_ak$noise_test)

```

```{r Basic_interpolation}
#Important: this needs to be loaded in before you use this function
ak_wavenumbers <- as.numeric(wavenumber_df_ak$AS.01)

interpolate <- function(wavenumber, absorbance) {
  tuple <- approx(as.numeric(wavenumber), as.numeric(absorbance), xout = ak_wavenumbers)
  df <- as.data.frame(tuple)
  df <- df %>%
    rename(wavenumber = x, absorbance = y)
}

interpolated_greenland <- lapply(filelist, function(x){interpolate(x$wavenumber, x$absorbance)})
```
