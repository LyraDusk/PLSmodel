---
title: "model assessment"
author: "Rana Gahwagy"
date: "2/21/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(Metrics)
library(pls)
library(qut)
library(varEst)
```

## build the model

```{r}

test_model <- akGLpls
df_used <-  akGL_wetChemAbs
actual_bsi_only <- akGL_wetChemAbs$BSi
```

# decide on number of components: 
## check Root Mean Square Error of Prediction (RMSEP) plot
produces number of plot for each dependent variable to give the error for each number of plot
```{r}
plot(RMSEP(test_model))
RMSEP(test_model)
```
## how do coeffecients change by number of components?
Plot to see how the regression coefficients are different based on the number of components retained. On the x-axis is each varuable which corresponds to each wave number. The more vatiance there is the more complex it is.  

```{r}
#choose a range for the number of components (ncomp) based or just one
plot(test_model, plottype = "coef", ncomp=c(1:6), legendpos = "topright")
```
## grid search 
a tool to search for the best predictive performance that can be used to tune the 'ncomp' hyperparameter. This uses a training, testing and validation sets, so it redefines the model 

```{r}
#split the data to training (70%), validation (10%), testing (20%)

spec = c(train = .7, test = .2, validate = .1)

g = sample(cut(
  seq(nrow(df_used)), 
  nrow(df_used)*cumsum(c(0,spec)),
  labels = names(spec)
))

res = split(df_used, g)

train <- res$train #70%
val <- res$validate # 10%
test <- res$test#20%

# Split the column names in X and Y
X_colnames <- colnames(df_used)[2:length(df_used)] #BSi absorbance at each wavenumber
Y_colnames <- colnames(df_used)[1] # BSi percentage  

# Split each train, val, test into two matrices
X_train_matrix <- as.matrix(train[X_colnames])
Y_train_matrix <- as.matrix(train[Y_colnames])

X_val_matrix <- as.matrix(val[X_colnames])
Y_val_matrix <- as.matrix(val[Y_colnames])

X_test_matrix <- as.matrix(test[X_colnames])
Y_test_matrix <- as.matrix(test[Y_colnames])

# Loop through possible values for n_comp to optimize R2 on validation data
best_r2 <- 0
best_ncomp <- 0
for (ncomp in c(2:(test_model$ncomp-2))){ # you can change number of components you want to test here
  ## redefine the model: 
  model <- plsr(Y_train_matrix ~ X_train_matrix , ncomp=ncomp, validation='CV' ) #validation method changes r2
  predictions <- as.matrix(data.frame(predict(model, ncomp=ncomp, X_val_matrix))) ##uses validation matrix 
  mean_r2 <- mean(diag(cor(predictions, Y_val_matrix))**2)
  if(mean_r2 > best_r2){
    best_r2 <- mean_r2
    best_ncomp <- ncomp
  }
}

#prints best component number based on R^2
print(best_ncomp)
print(best_r2)
```
or using algorthim from the pls package
```{r}
selectNcomp(test_model, method = "onesigma", plot = TRUE)
selected_ncomp <- selectNcomp(test_model, method = "onesigma", plot = FALSE)
```

## check for test score using the best number of components
```{r}
# Predict on test for having a final R2 estimate
best_model <- plsr(Y_train_matrix ~ X_train_matrix, ncomp=best_ncomp,  validation='CV', segments = 10)
test_predictions <- as.matrix(data.frame(predict(best_model, ncomp=best_ncomp, X_test_matrix))) #uses test matrix  
mean_r2 <- mean(diag(cor(test_predictions, Y_test_matrix))**2)
# print predictive average R2 score:
print(mean_r2)
```

## % variance explained: contribution of each additional varible 
```{r}
explvar(test_model)
explvar(best_model)
var <- as.vector(explvar(test_model))
ncomps <- 1:length(var)
plot(x=ncomps, y=var, type = "b")

```
## loading plot
The Loading Plot is a plot of the relationship between original variables and subspace dimensions. It is used for interpreting relationships among variables. Highly correlated variables have similar weights in the loading vectors and appear close together in the loading plots of all dimensions.

How much do each varible contributes to the linear combenation (focus on abs values). Similar values indicate that the varible contribute the same extent 
```{r}
plot(test_model, "loadings", comps = 2:7, legendpos = "bottomleft", xlab = "nm")
abline(h = 0)
```

## pair wise score plot 
used to look for patterns, groups or outliers in the data. look for clustering, outliers,or time-based patterns. the percentages are the relative amount of X variance explained by each component.
```{r}
plot(test_model, plottype = "scores", comps = 2:7)
plot(test_model, plottype = "scores", comps = selected_ncomp)
```
## Cross-validated predictions
```{r}
plot(test_model, ncomp = 1:7, asp = 1, line = TRUE)

```

## R^2: 
from package/function describtion: "unadjusted R^2. It is overoptimistic and should not be used for assessing models"
```{r}
R2(test_model)
validationplot(test_model, val.type="R2")  ## check vivian's r^2 +  understad where it is coming from
```

## correlation plot 
"works exactly like  scoreplot method. The “correlation loadings”, i.e. the correlations between each variable and the selected components (see References), are plotted as pairwise scatter plots, with concentric circles of radii given by radii. Each point corresponds to a variable. The squared distance between the point and origin equals the fraction of the variance of the variable explained by the components in the panel."

this plot tells you the  explained varince / correlation between each varible (each dot) and component. The inner radi is 50% and outer radii is 100% (defualt setting)
```{r}
corrplot(test_model, comps = 2:4 )
```

# residuals
the mean residuals for each component number
```{r}
for (i in 2:test_model$ncomp){ 
    predicted_bsi <- as.data.frame(test_model$fitted.values)
    #select model with 3 components
    predicted_bsi <- as.data.frame(predicted_bsi[,c(i)])
    #Rename wet_chem_data columns
    names(predicted_bsi)[1] <- "BSiPercent_Predicted"
    #Combine actual and predicted BSi wetchem data
    BSi <- cbind(row.names(df_used),actual_bsi_only, predicted_bsi)
    names(BSi)[1] <- "dataset"
    names(BSi)[2] <- "BSiPercent_Actual"
    BSi$dataset <- as.character(BSi$dataset)
    #reformat into long so we can graph
    BSi_Long <- BSi %>%
      dplyr::select(dataset, BSiPercent_Actual, BSiPercent_Predicted)%>%
      gather(key = "variable", value = "value", -dataset)
    #Create dataframe with residual error ----
    #Calculating Residuals: Difference between actual and predicted
    BSi$Difference <- (BSi$BSiPercent_Predicted - BSi$BSiPercent_Actual)
    #Table of differences for each sample
    Difference <- BSi %>%
      dplyr::select(dataset, Difference)
    Difference <- round_df(Difference, 2)
    #Calculate absolute values then mean  of residual errors ----
    Abs <- (abs(Difference$Difference))
    print(paste("for comp ", i, " the average residual is ", mean(Abs)))
}
```

or using the function from package (numbers are slightly different than calculated)
```{r}
model_res <- residuals(test_model)
mean_residuals_df <- data.frame(ncomp = 1:test_model$ncomp, mean_residuals = 1:test_model$ncomp)
for(i in 1:test_model$ncomp){
  mean_residuals_df$mean_residuals[i] <- mean(abs(model_res[,1,i]))
}
mean_residuals_df <- round_df(mean_residuals_df, 2)
mean_residuals_df
```

creating a residual graph for the best components
```{r}
# chosen best number of components
i <- selected_ncomp
predicted_bsi <- as.data.frame(test_model$fitted.values)
    #select model with 3 components
    predicted_bsi <- as.data.frame(predicted_bsi[,c(i)])
    #Rename wet_chem_data columns
    names(predicted_bsi)[1] <- "BSiPercent_Predicted"
    #Combine actual and predicted BSi wetchem data
    BSi <- cbind(row.names(df_used),actual_bsi_only, predicted_bsi)
    names(BSi)[1] <- "dataset"
    names(BSi)[2] <- "BSiPercent_Actual"
    BSi$dataset <- as.character(BSi$dataset)
    #reformat into long so we can graph
    BSi_Long <- BSi %>%
      dplyr::select(dataset, BSiPercent_Actual, BSiPercent_Predicted)%>%
      gather(key = "variable", value = "value", -dataset)
    #Create dataframe with residual error ----
    #Calculating Residuals: Difference between actual and predicted
    BSi$Difference <- (BSi$BSiPercent_Predicted - BSi$BSiPercent_Actual)
    #Table of differences for each sample
    Difference <- BSi %>%
      dplyr::select(dataset, Difference)
    Difference <- round_df(Difference, 2)

    print(Difference %>%
      mutate(highlight_flag = ifelse(Difference >= '0', T, F)) %>%
      ggplot (aes(x = dataset, y = Difference)) +
      geom_col(aes(fill = highlight_flag)) +
      scale_fill_manual(values = c('red', 'darkgreen'), name = "Overfitting") +
       #geom_text( data = Difference, aes(label = Difference), fontface ="bold", size = 2.5, vjust = 0) +
      labs(
        y = "Difference in Percentage",
        x = "Sample",
        title=expression("Residuals: Full Spectrum" ~ cm^{-1}),
        subtitle= paste0("For each sample with ", i, " components and mean residual of  ", mean_residuals_df$mean_residuals[i], " cm^1"),
        colour = "variabl") +
        theme_bw() +
        scale_y_continuous(breaks = scales::pretty_breaks(n = 10))+
        theme(axis.text.x = element_blank()
              #,legend.position = c(0.1, 0.85), axis.text.x  = element_text(angle = 90)
              ) 
        
     )
```

```{r}

pls_bsi <- data.frame( wet_chem = actual_bsi_only, pls = unlist(predicted_bsi))

pls_lm <- lm(pls ~ wet_chem, pls_bsi)
pls_bsi_r <- summary(pls_lm)$r.squared

ggplot(pls_bsi, aes(x=wet_chem, y = pls)) +
  geom_point()+
  geom_smooth(method = "lm", se = FALSE, color = "darkGreen") +
  geom_text(x = 5, y = 25, label = paste("R^2: ",round_df(pls_bsi_r, 3)))+
  xlab("Wet Chemical BSi Percent (%)") +
  ylab("PLS Predicted BSi Percent (%)")+
  ggtitle("Predeicted Fitness Using PLS Model")+
  theme_bw()
```

```{r}
x_mat <- as.matrix(df_used %>% dplyr::select(-1))
y_mat <- as.matrix(df_used %>% dplyr::select(1))
rcv(x_mat, y_mat, a= NULL,d= 2, method = "spam")
```

Calculate test MSE for best components 
```{r}
pls_pred = predict(test_model, X_test_matrix, ncomp = 2)
mean((c(pls_pred) - Y_test_matrix)^2)

```

